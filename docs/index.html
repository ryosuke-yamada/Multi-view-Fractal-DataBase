
<html>

<head>
    <title>MV-FractalDB</title>
    <link rel="StyleSheet" href="style.css" type="text/css" media="all">
    <link rel="shortcut icon" type="image/png" href="./img/cc_logo_1_crop.png">
    <meta property="og:title" content="MV-FractalDB: Formula-driven Supervised Learning for Multi-view Image Recognition">
    <!-- Place this tag in your head or just before your close body tag. -->
<!--     <script async defer src="https://buttons.github.io/buttons.js"></script> -->
</head>
<body>
    <br>
    <div class="center-div">
        <span style="font-size:32px">MV-FractalDB: Formula-driven Supervised Learning for Multi-view Image Recognition</span>
    </div>

    <br>
    <table align="center" width="800px">
        <tbody>
            <tr>
                <td align="center" width="200px">
                    <div class="center-div">
                        <span style="font-size:22px"><a href="https://scholar.google.com/citations?user=2nmJ6qQAAAAJ&hl=ja">Ryosuke Yamada</a></span>
                    </div>
                </td>

                <td align="center" width="200px">
                    <div class="center-div">
                        <span style="font-size:22px"><a href="#">Ryo Takahashi</a></span>
                    </div>
                </td>

                <td align="center" width="200px">
                    <div class="center-div">
                        <span style="font-size:22px"><a href="#">Ryota Suzuki</a></span>
                    </div>
                </td>

                <td align="center" width="200px">
                    <div class="center-div">
                        <span style="font-size:22px"><a href="http://www.is.fr.dendai.ac.jp/">Akio Nakamura</a></span>
                    </div>
                </td>
            </tr>
        </tbody>
    </table>
    <br>
    
    <br>
    <table align="center" width="800px">
        <tbody>
            <tr>
                <td align="center" width="200px">
                    <div class="center-div">
                        <span style="font-size:22px"><a href="#">Yusuke Yoshiyasu</a></span>
                    </div>
                </td>
                
                <td align="center" width="200px">
                    <div class="center-div">
                        <span style="font-size:22px"><a href="https://staff.aist.go.jp/ryusuke.sagawa/">Ryusyke Sagawa</a></span>
                    </div>
                </td>
                
                <td align="center" width="200px">
                    <div class="center-div">
                        <span style="font-size:22px"><a href="http://hirokatsukataoka.net/">Hirokatsu Kataoka</a></span>
                    </div>
                </td>                
            </tr>
        </tbody>
    </table>
    <br>
    <table align="center" width="800px">
        <tbody>
            <tr>
                <td align="center" width="800px">
                    <div class="center-div">
                        <span style="font-size:15px">Tokyo Denki University &nbsp; &nbsp; National Institute of Advanced Industrial Science and Technology (AIST) &nbsp; &nbsp; Keio University</span>
                    </div>
                </td>
            </tr>
        </tbody>
    </table>

    <br>
    <table align="center" width="800px">
        <tbody>
            <tr>
                <td>
                    <div class="center-div">
                        <a href="#"><img src="resources/images/mvfractal.gif" width="700px"></a><br>
                    </div>
                </td>
            </tr>

        </tbody>
    </table>
    <br><br>

    <hr>
    <div class="center-div">
        <h1>Abstract</h1>
    </div>
    <p>
        Multi-view image recognition is one of the solutions in order to avoid leaving weak viewpoints in robotics applications such as object manipulation, mobile robot services, and navigation robots. For example, a mobile robot in a home must judge an object category and the posture with a given image for household chores. The paper proposes a method for automatic multi-view dataset construction based on formula-driven supervised learning (FDSL). Although a data collection and human annotation of 3D objects are de nitely labor-intensive, we simultaneously and automatically generate 3D models,multi-view images, and their training labels in the proposed multi-view dataset. In order to create a large-scale multi-view dataset, we employ fractal geometry, which is considered the background information of many objects in the real world. It is expected that this background knowledge of the real world would allow convolutional neural networks (CNN) to acquire a better represen- tation in terms of any-view image recognition. We project in a circle from the rendered 3D fractal models to construct the Multi-view Fractal DataBase (MV- FractalDB), which is then used to make a pre-trained CNN model for improving the problem of multi-view image recognition. Since the dataset construction is automatic, the use of our MV-FractalDB does not require any 3D model de nition or additional manual annotations in the pre-training phase. According to the experimental results, the MV-FractalDB pre-trained model surpasses the accuracies with self- supervised methods (e.g., SimCLR and MoCo) and is close to supervised methods (e.g., ImageNet pre- trained model) in terms of performance rates on multi-view image datasets. Also, it was con rmed that MV-FractalDB pre-trained model has better convergence speed than the ImageNet pre-trained model on ModelNet40 dataset. Moreover, we demonstrate the potential for multi-view image recognition with FDSL.
    </p>
    <br><br>

    <hr>
    <div class="center-div">
        <h1 id="arch">Multi-view Fractal DataBase</h1>
    </div>
    <div class="center-div">
        <img class="round" style="wide:500px" src="resources/images/render4.png">
    </div>
    <br><br>

    <hr>
    <div class="center-div">
        <h1 id="paper">Paper and Code</h1>
    </div>
    <table align="center" width="600px">

        <tbody>
            <tr>
                <td>
                    <img class="layered-paper-big" style="height:175px" src="resources/images/image1.png">
                </td>
                <td>
                    <span style="font-size:14pt">R. Yamada, R. Takahashi, R. Suzuki, A. Nakamura, Y. Yoshiyasu, R. Sagawa, H. Kataoka</span>
                    <br><br>
                    <b><span style="display:inline-block;width:600px;font-size:14pt">MV-FractalDB: Formula-driven Supervised Learning for Multi-view Image Recognition</span></b>
                    <br><br>
                    <span style="font-size:14pt">IROS 2021</span>
                    <br><br>
                    <span style="font-size:20px">
                        <a href="">[Paper]</a> &nbsp; &nbsp;
                        <a href="">[GitHub]</a> &nbsp; &nbsp;
                        <a href="">[Dataset]</a> &nbsp; &nbsp;
                    </span>
                </td>
            </tr>
        </tbody>
    </table>
    <br><br>

    <hr>
    <div class="center-div">
        <h1 id="code">Results</h1>
    </div>
    <div class="center-div" style="width:1100px">
        <table align="center" width="1100px">
            <tbody>
                <tr>
                    <td>
                        <div class="center-div">
                            <img src="resources/images/result1.png" width="550px"><br>
                        </div>
                    </td>
                    <td>
                        <div class="center-div">
                            <img src="resources/images/acc_compare_ModelNet40_12.png" width="550px"><br>
                        </div>
                    </td>
                </tr>
                <tr>
                    <td>
                        <div class="center-div">
                            <span style="font-size:14px"><i>Results on ModelNet/MIRO dataset.</i>
                            </span></div>
                    </td>
                    <td>
                        <div class="center-div">
                            <span style="font-size:14px"><i>Results on ModelNet dataset.</i>
                            </span></div>
                    </td>
                </tr>
            </tbody>
        </table>
    </div>

    <br><br>
<!--     <hr>
    <table align="center" width="980px">
        <tbody>
            <tr>
                <td>
                    <left>
                        <div class="center-div">
                            <h1>Video</h1>
                        </div>
    <iframe width="956" height="538" src="" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

                    </left>
                </td>
            </tr>
        </tbody>

    </table>
        <br><br>
    <hr> -->
    <table align="center" width="980px">
        <tbody>
            <tr>
                <td>
                    <left>
                        <div class="center-div">
                            <h1>Acknowledgements</h1>
                        </div>
                        <div class="center-div">
                         This work was supported by JSPS KAKENHI Grant Number JP19H01134.
                        Computational resource of AI Bridging Cloud Infrastructure (ABCI) provided by National Institute of Advanced Industrial Science and Technology (AIST) was used.
                        The website is modified from this <a href="https://walsvid.github.io/Pixel2MeshPlusPlus/">template</a>.
                        </div>
                    </left>
                </td>
            </tr>
        </tbody>
    </table>
    <br>



</body>

</html>
